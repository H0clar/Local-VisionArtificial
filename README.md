La aplicación incluye una función que permite guardar imágenes de objetos detectados en una carpeta específica. Además, en tiempo real, captura fotogramas de una cámara y utiliza un modelo YOLO para identificar objetos en cada fotograma. Si la confianza de la detección supera un umbral predefinido, la aplicación almacena los detalles de la detección en una base de datos y guarda una imagen del objeto detectado. Finalmente, muestra el fotograma original junto con las detecciones de objetos en una ventana gráfica en tiempo real. Esta combinación de funciones permite un seguimiento efectivo de objetos en un flujo de video en vivo y facilita la documentación de las detecciones para su análisis posterior o integracion con otras tecnologias (arduino).




https://github.com/H0clar/Local-VisionArtificial/assets/118459488/9ddd7cf9-b57d-4366-a859-53bad7da8e61




![db](https://github.com/H0clar/Local-VisionArtificial/assets/118459488/2f92a646-232c-4cbf-b86e-db914529e577)



El proyecto de mi compañero Esteban Acevedo posee capacidades que podrían abrir la puerta a la integración de proyectos a través de microcontroladores. Esto se logra mediante un brazo robótico ya impreso y en funcionamiento, el cual se puede controlar a través de una aplicación móvil conectada a Firebase, adjunto repo de mi compañero.


https://github.com/EstebanAcevedo94/Mando_Brazo
